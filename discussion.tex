\chapter{Discussion}\label{sec:discussion}

In this chapter, we discuss advantages and disadvantages of the different 
models developed  and compared to in this thesis, and justify our 
contributions. In addition, we address possible criticisms and other tradeoffs 
and design choices that are of importance beyond pure accuracy.  Performance of 
the different models in terms of part localization accuracy is 
in~\secref{system-results}.

\section{The case for image-dependent interactions}

At the time of publication, CPS was significantly better than all modern ``in 
the wild'' pose estimation approaches 
\citep{ferrari08,eichner09,devacrf,andriluka09}.  CPS was the only one to use 
image-dependent pairwise cues.  These other systems focused on either 
pre-processing to reduce the state space or improving unary potentials via 
foreground color estimation, and all performed inference relying ultimately on 
edge-based unary potentials and simple geometric displacement pairwise cues as 
in the classical PS model (\secref{ps}).
\out{
Recently, \citet{deva2011} introduced a multi-modal model of pose that competes 
with CPS. However, empirical results indicate that CPS generalizes better than 
\citet{deva2011}: when both models are trained on Buffy, CPS outperforms 
\citet{deva2011} on Pascal. Furthermore, two years after its introduction in 
the literature, CPS is still the best performing model in the less precise 
regime (\figref{results-buffy-pascal}).  One of the reasons for the lack of 
precision is the coarser nature of our features: whereas \citet{deva2011} can 
evaluate placements to the granularity of a HoG cell, many of our features are 
more coarsely described and/or discretized---\eg, is the part guess near a 
contour, is the part guess in the foreground color.
}
In a controlled setting, we see that a classical PS model coupled with just one 
image-dependent interaction feature, such as contour continuity, significantly 
improves performance (\figref{ablative}).  This makes a strong case that 
image-dependent interactions improve performance.

The benefits of image-dependent interactions is further reinforced by the 
performance by our video pose estimation model.  The Ensemble of Stretchable 
Models exploits a variety of across-body and across-frame image interactions 
and significantly outperfoms methods with fewer interactions.

Finally, we see effective data-dependent switching of modes in our LLPS model.  
The decision of which local model $s^z(x,y)$ to choose depends on large-context 
interactions considering a whole half-body in scope. These holistic cues are 
crucial in determining an effective mode to use, and serve as one of the main 
reasons LLPS outperforms~\citet{deva2011}.

We believe our cascade approach is a very useful tool that helps us design 
models with larger image-dependent interactions.  It is a key component to all 
models presented here to achieve a high degree of accuracy and/or efficiency.  
The cascade framework also holds potential to improve the richness of models in 
the future.  In general, our approach is a principled framework that frees us 
from restricting our models to limited pairwise potentials of the form $||y_i - 
y_j||$.  This allows much more flexibility in the future to incorporate more 
pairwise and even higher-order features. 

\section{More features or more modes?}
As discussed in~\secref{llps}, there are two major approaches for improving 
pose accuracy in recent years: adding more features, \eg CPS, ESM and 
\citet{ferrari08,eichner09,ddtran}, or adding more modes, \eg LLPS and 
\citet{dpm,wang2011,deva2011,johnson11}.  

LLPS and~\citet{deva2011} are both multimodal models that outperform the 
feature- and computation-heavy CPS.  It is unclear given the current 
state-of-the-art if the multimodal HoG model approach is yet saturated, or more 
data and more nuanced mode definitions will continue to yield increased 
performance in coming years.  \citet{zhuwe} has an excellent study of whether 
these models are near saturation; see \figref{llps-learning-curve} for our own 
trend analysis.  Both suggest that we are not near saturation yet, in terms of 
number of parts, modes and training data. There are also no limit to the 
performance gains to be had by adding more and better features, only 
computational hurdles.

\begin{figure}[htb!]
\centering
\includegraphics[width=0.59\linewidth]{figs/llps-learning-curve.pdf}
\caption[Test accuracy versus number of local neighborhood modes in LLPS.]{
\label{fig:llps-learning-curve} \todo{DO THIS WITH LLPS}}
\end{figure}


Ultimately, these research directions are complementary, and an ideal model 
would use a combination of rich features and multiple modes. Each additional 
feature type (\eg, segments, contours, optical flow, depth) incurs an 
additional cost to obtain, but adds to the generalization capabilities of the 
model. Additional modes allow for more specific modeling of different 
scenarios, but require more training data to estimate parameters accurately.  
This leaves a large space of possible models combining the two approaches.

\section{Joints or limbs?}

The ESM model introduced a joint-based 2D representation of pose.  At the same 
time, \citet{deva2011} also introduced a model based on joints and limb 
midpoints as basic units of inference.  This approach has clear benefits for 
easily capturing foreshortening and scale.  It has the seeming disadvantage of 
not being able to capture limb-pair features with a pairwise model.  However, 
this is not a fundamental limitation.  Especially using cascaded inference 
techniques we should not shy away from describing higher order cliques in the 
future.  In general, the scope of the basic atomic unit for inference (the 
inference variables) need not be dictated by the scope of the largest clique we 
capture in our model.  Joint-based models are worth exploring further.  In 
particular, we expect an Ensemble of Stretchable Models approach applied to 
{\em single frame} pose estimation to work well.

\section{Detection, localization, or both?}

Some pose estimation systems advertise that they work well for both person 
detection {\em and} pose estimation---in particular \citet{andriluka09} and 
\citet{deva2011}.  One system that does both is beneficial in its 
simplicity---one function to both find a person and find their body parts.  Our 
approach, on the other hand, requires first detecting a person with a dedicated 
person detector, and then running our pose models on the detected person. 

We believe that detection and localization are fundamentally different tasks 
and should be decoupled.  In detection, we wish to generalize over all poses 
and determine how to discriminate any pose from background clutter---a 
detection is correct even when a pose is incorrect, and a detector must also 
have some notion of global confidence to determine, over all possible image 
patches, whether it is a person or not.  A pose estimator works under the 
assumption that a pose is present, and is correct only if it predicts the right 
pose versus combinatorially many wrong poses.

One model that attempts to perform both tasks is bound to perform only as well 
as it could tuned to each task independently, and probably worse.  It may be 
that PS models are the right {\em family} of models for both detection and 
localization---they have attractive benefits for generalizing over poses with 
deformations and obstructions in addition to localizing pose---and they should 
be used for both.  However, models should be trained evaluated specific to a 
single task.

\section{Everything and the kitchen sink: a bug or a feature?}
One of the selling points of our models is the ability to include a multitude 
of features.  The goal is to include as many feature modalities as possible in 
our CPS and ESM models.  Having so many features makes it difficult to 
determine exactly what is contributing to the success of our model.  

From a machine learning standpoint, this is an attractive aspect of our system: 
given training data, we can try everything and see what works.  From a computer 
visionist's (or perceptual scientist's) perspective, this is a 
disadvantage---it is difficult to gain insight into why the model is performing 
well.

We take a functional, application-driven approach towards computer vision, and 
consider our problem one of engineering rather than perceptual science.  The 
inability to measure the individual performance of components in any complex 
system is inevitable---the whole is greater than the sum of its parts.  We 
provide individual feature analysis in~\figref{ablative}, and make convincing 
arguments that the features and interactions we include are beneficial.  We 
make no statement as to which features are the ``best'', in any sense other 
than their contribution to final system performance.

\section{Accuracy, speed, simplicity}
\begin{figure}[htb!]
\centering
\includegraphics[width=0.95\linewidth]{figs/speed-vs-acc.pdf}
\caption[Speed versus accuracy.]{
\label{fig:speed-v-acc} Test time speed versus accuracy.  Accuracy is measured 
as area under the pixel error threshold curve (AUC).  Speed is in seconds on an 
AMD Opteron 4284 CPU @ 3.00 GHz with 16 cores.  On the left, we compare 
different methods with a log time scale.  The upper left corner is the most 
desirable operating point.  LLPS is strictly better than other methods in the 
speed-accuracy space.  On the right, we zoom in to investigate our cascaded 
LLPS approach.  By tuning the aggressiveness ($\alpha$) of the cascade, we can 
get a curve of test time speed-accuracy points.  Also, we see that ``full 
training''---considering all modes in every training example---rather than
``cascaded training''---just the ones selected by the cascade step---leads to 
roughly a $1.5\%$ performance increase (at the cost of $5\times$ slower 
training).}
\end{figure}

When developing our CPS and ESM models, we focused our attention on obtaining 
the best performing, computationally tractable system.  Besides raw 
performance, practitioners care as much about {\em speed}---does the system run 
quickly?---and {\em simplicity}---how long does it take to download, compile, 
understand, run and/or re-implement?  One of the motivations of LLPS and 
attractiveness of~\citet{deva2011}'s model is its speed and simplicity, in 
terms of image features (only HoG) and lines of code.

LLPS is strictly better than other models in terms of speed and simplicity, 
according to \figref{speed-v-acc}. \citet{deva2011} is strictly better than all 
but LLPS.  Among the other models, there is no clear winner---CPS is more 
accurate but slower.  Predicting cluster means is extremely fast but less 
accurate.

We believe that, moving forward, models with any combination of the three 
contributions {\em accuracy, speed, simplicity} are all worthwhile, even 
independent of the others. Any current system's slowness today will likely be a 
non-issue in 5-10 years with the advent of faster CPUs and more cores.  
Anecdotally, at time of publication two years ago, the CPS system took 5 
minutes and 15 seconds.  Today, at roughly the same price and consumer 
availability, the system runs in 3 minutes.


\out{
\chapter{Future directions}

what will it take to work?
  + more data
  + more computation

does the right cost function exist?
}
\chapter{Conclusion}

This thesis proposes advancements in 2D human pose estimation models to improve 
upon state-of-the-art performance.  Specifically, previously proposed pictorial 
structures models are handicapped by the needs of efficient inference tricks; 
forced to express simple pairwise cues that are only a function of parts' 
spatial relationships.  Further, the spatial relationship structure had to form 
a tree graph.

We push past the inference barrier in several ways, allowing us to include 
richer image-dependent interactions.  First, we proposed Cascaded Pictorial 
Structures ({\bf CPS}), a sequence of structured models that efficiently prune 
the state space of possible poses down to a manageable number.  This allows us 
to perform efficient exact inference without restrictions.  We exploit this by 
incorporating a variety of rich features from complementary sources, improving 
upon state-of-the-art PS approaches in single frame pose estimation.

We then extend this approach to handle pose estimation in video.  Maintaining a 
rich set of variable interactions in video creates a cyclic network, which is 
known to require inference inference exponential in the number of frames of 
video.  We maintain tractability through the use of a cascade step as in CPS, 
and an approximate inference method which decomposes the cyclic structure of 
interactions into an ensemble of tree graphs, which capture all the 
interactions of the cyclic network, with redundancies.  With this Ensemble of 
Stretchable Models ({\bf ESM}), approximate inference is only linear in the 
number of frames of video.  Furthermore, to handle fine-grained articulation 
and foreshortening effects often present in real video clips, we use a 
joint-based representation of pose, as opposed to a limb-based representation, 
hence our model is ``stretchable''.

Finally, we explore a complementary approach to the line of research that 
motivated CPS and ESM.  These methods focused on novel computational techniques 
that allowed us to add more and more features and rich interactions into our 
pose models, in the hope that more features would lead to better 
generalizability and performance accuracy.  Alternatively, in Local Linear 
Pictorial Structures ({\bf LLPS}), we focus instead explicitly on the 
non-linear, multi-modal nature of the problem, {\em not} by introducing more 
and more features, but instead modeling each local neighborhood with it's own 
PS model.  Local neighborhoods are defined as a function of closeness in 
appearance and pose centered at every training example, allowing us to 
preciesely model different modes of the input that result from different 
clothing, body types, and pose.

We show empirically that our models are state-of-the-art on competitive public 
datasets, verifying the worthiness of our modeling innovations: (1) cascades of 
structured models (2) ensemble of tree models (3) joint-based representations 
(4) local linear modeling.  All of these ideas are valuable contributions to 
the field of pose estimation, with potential to help in other domains involving 
structured problems as well.

Human pose estimation in the wild in its most general setting is still far from 
a solved problem, although we have made significant advances through the course 
of this research.  Moving forward, we expect further advances to be made with 
(1) larger datasets, (2) the computational capabilities to scale current 
approaches to an order of magnitude more data, and (3) reconciling estimates of 
pose within the larger context of scene understanding.

Future improvements in pose accuracy seem promising and the dream of 
understanding human pose for a variety of applications is increasingly 
compelling given the advancements in robotics and the pervasiveness of cameras 
in our lives.  In conclusion, the future of pose estimation is bright.
